quarkus.langchain4j.jlama.include-models-in-artifact=true

# TODO: check this breaks the tests
# quarkus.langchain4j.jlama.chat-model.max-tokens=1024
%test.quarkus.langchain4j.jlama.chat-model.temperature=0.0
